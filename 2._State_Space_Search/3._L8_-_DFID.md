# 3. L8 - DFID
Created Wednesday 07 October 2020


* The search process generates a search tree. We've used this to calculate the complexity.
* Keeping OPEN and CLOSED as lists is not efficient.


*****

**Depth Bound Depth First Search(DBDFS)**
The bound is finite, provided by us.
Why do we do this?

* It's linear in space.
* It's complete(i.e search will conclude for sure).

DBDFS pseudocode
	OPEN = [S] /* start node inside OPEN stack */
	CLOSED = {} 
	func DBDFS(maxDepth):
		depth = 0
		N = null
		while goalTest(N)==false and OPEN.empty==false:
			N = OPEN[0] /* like OPEN.pop() */
			if goalTest(N)==true:
				return N
			OPEN.remove(N)
			CLOSED.add(N)
			if depth > maxDepth or N.isLeaf()==false :
				OPEN = moveGen(N).removeSeen() + OPEN
				depth+=1
			else:
				depth-=1 /*backtrack*/
		return null /* Goal not found*/


* This is just like DFS except for the depth parameter.


*****

**Depth First Iterative Deepening(DFID)**
Suppose we set the maxDepth to some value, but the Goal is not found. We can try maxDepth+1, and continue
i.e we go deeper at each iteration - i.e a series of DFSs. This algorithm is called DFID.

DFID pseudocode
	func DFID:
		depth = 1
		G = null /* for storing the goal state*/
		while OPEN.empty==false && G==null:
			OPEN = [S] /* need to reset both OPEN and CLOSE*/
			CLOSED = []
			G = DBDFS(depth)
		return G /* handles both cases, found and not found*/


**Analyzing DFID**

* Space Complexity - linear, just like DFS. To visualize max(DFS~1~, DFS~2~, ... DFS~maxDepth~) = DFS~maxDepth~
* Quality of solution - Optimal. In each deepening we scan the largest layer(at that time), i.e  the search frontier is just like BFS. As BFS is optimal, DFID is optimal.
* Time Complexity - Same as O(T(DFS)). (i=0 to end)âˆ‘b^i^=b^end+1^ = Time(DFS)*b/b-1 = Same as DFS asymptotically. Not a problem at all.
* Completeness - complete, it is bounded.



*****

**Facts about DFID**

* DFID is DFS masquerading as BFS. It has all the benefits of DFS and BFS combined, and has no drawback of either, namely linear space, completness and optimality. Time complexity was same for both DFS and BFS. **Best of both algorithms**
* This algorithm was created to solve the problem of chess moves, where we can search the best move until our 'move time' is over, which is the case for chess tournaments. We can stop the algo when time ends.
* For practical reasons, we'll keep the CLOSED a hash table.



*****

Practicality of blind searches:

* Solving a rubiks cube with the fastest world will take 18^20^ node scans ~ 40 Billion centuries.
* Solving 15-puzzle takes 10^13 ^moves
* Solving 24-puzzle takes 10^24^ moves
* **This is just nuts.**
* But people have devised ways of solving a Rubiks cube optimally, by using heuristics.
* The goal state(or description) has no effect on a blind search, that is the reason why it is so inefficient.

**Being blind is the problem**

